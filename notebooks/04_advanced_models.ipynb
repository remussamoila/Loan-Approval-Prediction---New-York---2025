{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Clone the repo (safe to re-run if it already exists)\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"Loan-Approval-Prediction---New-York---2025\"):\n",
        "    !git clone https://github.com/remussamoila/Loan-Approval-Prediction---New-York---2025.git\n",
        "\n",
        "%cd Loan-Approval-Prediction---New-York---2025"
      ],
      "metadata": {
        "id": "3x8rLuGiuZ-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# âš™ï¸ Advanced Modeling - Loan Approval\n",
        "\n"
      ],
      "metadata": {
        "id": "FNVADJdQuCNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/remussamoila/Loan-Approval-Prediction---New-York---2025/blob/main/notebooks/04_advanced_models.ipynb)"
      ],
      "metadata": {
        "id": "dLKijQyaunoI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOkOrXL0tyaQ"
      },
      "source": [
        "# ðŸ“˜ 04_advanced_models.ipynb\n",
        "\n",
        "**Goal**: Train and compare advanced models (XGBoost and LightGBM) for the SME Loan Approval task. Evaluate with Mean F1 Score.\n",
        "\n",
        "This notebook includes:\n",
        "- Data loading and preprocessing\n",
        "- Training XGBoost and LightGBM\n",
        "- Hyperparameter tuning (GridSearchCV)\n",
        "- Model comparison and export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDyswTfwtyaW"
      },
      "source": [
        "# âœ… Step 1: Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ0BvHUGtyaZ"
      },
      "source": [
        "# âœ… Step 2: Load and preprocess data\n",
        "df = pd.read_csv('data/train.csv', low_memory=False)\n",
        "df['DisbursementGross'] = df['DisbursementGross'].replace('[\\$,]', '', regex=True).astype(float)\n",
        "df['BalanceGross'] = df['BalanceGross'].replace('[\\$,]', '', regex=True).astype(float)\n",
        "df.drop(columns=['id', 'LoanNr_ChkDgt', 'Name', 'City', 'DisbursementDate', 'ApprovalDate'], inplace=True)\n",
        "df.fillna(-1, inplace=True)\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    df[col] = df[col].astype(str)\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "X = df.drop(columns=['Accept'])\n",
        "y = df['Accept']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Wt3c01tyaa"
      },
      "source": [
        "# âœ… Step 2B: Train Baseline Models\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Dummy Classifier\n",
        "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy.fit(X_train, y_train)\n",
        "f1_dummy = f1_score(y_val, dummy.predict(X_val))\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "f1_lr = f1_score(y_val, lr.predict(X_val))\n",
        "\n",
        "# Decision Tree\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "f1_tree = f1_score(y_val, tree.predict(X_val))\n",
        "\n",
        "print(\"ðŸ“Š Dummy F1:\", f1_dummy)\n",
        "print(\"ðŸ“Š Logistic Regression F1:\", f1_lr)\n",
        "print(\"ðŸ“Š Decision Tree F1:\", f1_tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6-VvO0Otyaa"
      },
      "source": [
        "# âœ… Step 3: Train XGBoost\n",
        "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "model_xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = model_xgb.predict(X_val)\n",
        "f1_xgb = f1_score(y_val, y_pred_xgb)\n",
        "print('XGBoost F1 Score:', f1_xgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmjI499Ttyab"
      },
      "source": [
        "# âœ… Step 4: Train LightGBM\n",
        "model_lgb = LGBMClassifier(random_state=42)\n",
        "model_lgb.fit(X_train, y_train)\n",
        "y_pred_lgb = model_lgb.predict(X_val)\n",
        "f1_lgb = f1_score(y_val, y_pred_lgb)\n",
        "print('LightGBM F1 Score:', f1_lgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppObiEJjtyac"
      },
      "source": [
        "# âœ… Step 5A: Hyperparameter Tuning (XGBoost)\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [4, 6],\n",
        "    'learning_rate': [0.05, 0.1]\n",
        "}\n",
        "grid_xgb = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "                        param_grid_xgb, scoring='f1', cv=3)\n",
        "grid_xgb.fit(X_train, y_train)\n",
        "print('Best XGBoost params:', grid_xgb.best_params_)\n",
        "print('Best XGBoost F1:', grid_xgb.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5GM5wDxtyac"
      },
      "source": [
        "# âœ… Step 5B: Hyperparameter Tuning (LightGBM)\n",
        "param_grid_lgb = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [4, 6],\n",
        "    'learning_rate': [0.05, 0.1]\n",
        "}\n",
        "grid_lgb = GridSearchCV(LGBMClassifier(), param_grid_lgb, scoring='f1', cv=3)\n",
        "grid_lgb.fit(X_train, y_train)\n",
        "print('Best LightGBM params:', grid_lgb.best_params_)\n",
        "print('Best LightGBM F1:', grid_lgb.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqboHQNFtyad"
      },
      "source": [
        "# âœ… Step 6: Compare Models\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['Dummy', 'Logistic Regression', 'Decision Tree', 'XGBoost', 'LightGBM'],\n",
        "    'F1 Score': [f1_dummy, f1_lr, f1_tree, f1_xgb, f1_lgb]\n",
        "})\n",
        "sns.barplot(x='Model', y='F1 Score', data=results)\n",
        "plt.title('F1 Score Comparison (Baseline vs Advanced)')\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMpA1K-ytyae"
      },
      "source": [
        "# âœ… Step 7: Export the best model\n",
        "import joblib\n",
        "\n",
        "# Assuming LightGBM gave the best results â€” adjust if needed\n",
        "best_model = model_lgb if f1_lgb > f1_xgb else model_xgb\n",
        "joblib.dump(best_model, 'models/best_model.joblib')\n",
        "print(\"âœ… Best model saved to models/best_model.joblib\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}